# 一元线性回归
我们以前的函数研究确定性变量的函数关系，比如正方形面积和边长的关系。  
现在我们要研究随机变量之间的关系，这时不确定变量之间的关系，比如身高和体重。

先研究两个变量之间的。
现在两个随机变量Y和X，我们先将X固定，也就是X已经确定的情况下，令为x，这时看Y的分布，相当于一个条件概率。研究Y的分布于x的关系还是比较复杂，继续简化，我们求出一个确定的Y，这时就是一个确定性的变量之间的函数关系了，即确定性的Y与确定的x之间的关系。这个确定的Y选择谁呢，选择E(Y)。   

为什么选择E(Y)呢？ 这源于一个原理，对于随机变量$\eta$来说，当$c = E(\eta)时，E[(\eta-c)^2])$达到最小，即随机变量与它的期望的均方差是最小的。也就是说我求x与E(Y)的关系，最后出来的Y与实际的Y的均方差方差会最小，求其它的都更大  

最后，也就是说，作为一种近似，研究X与Y的关系，变为研究确定的x与对应的E(Y)之间的关系E(Y) = u(x), u(x)就叫做Y关于x的回归函数。

回归可以是不同形式的，现在，我们研究一元线性关系的，也就是假设回归函数为$\mu(x) = b_0+b_1x$,  这个一般可以用散点图或者专业知识等先验的判断出这种线性关系。$\mu$是期望，Y在期望周围上下波动，我们假设 $Y\text{\textasciitilde}N(b_0+b_1x, \sigma^2)$ 于是有条件概率密度函数$f(y|x) = \frac{1}{\sqrt{2\pi\sigma}} exp-\frac{(y-b_0-b_1x)^2}{2\sigma^2}$


现在有样本(x_1,y_1), ... ,(x_n,y_n),其同时出现的概率,也即似然函数为L=$\displaystyle\prod_{i=1}^n\frac{1}{\sqrt{2\pi\sigma}} exp\frac{(y_i-b_0-b_1x_i)^2}{2\sigma^2}$ 于是 $lnL = \frac{n}{\sqrt{2\pi\sigma}} -\displaystyle\sum_{i=1}^n\frac{(y_i-b_0-b_1x_i)^2}{2\sigma^2}$去除无关项，得到最大化释然函数，需要最小化$\displaystyle\sum_{i=1}^n(y_i-b_0-b_1x_i)^2$ 分别对$b_0$,$b_1$求导，可得